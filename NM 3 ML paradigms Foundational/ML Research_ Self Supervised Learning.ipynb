{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPd9847s1XovDJrj2MsM4ry"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","This project employs self-supervised learning to train a model for predicting the order of words in movie reviews, leveraging the IMDb dataset."],"metadata":{"id":"OXa1Z_tGFLNC"}},{"cell_type":"markdown","source":["# Step 1: Import necessary libraries and load dataset"],"metadata":{"id":"4crfs1rh41OH"}},{"cell_type":"markdown","source":["\n","\n","*   The IMDb dataset is loaded, consisting of movie reviews represented as sequences of integers. Only the top 5000 frequent words are considered (num_words=5000).\n","*   The integer sequences are converted back to human-readable text (decoded_train_reviews and decoded_test_reviews).\n","*   Words within each review are shuffled to create a self-supervised learning task.\n","*   Tokenization is applied to convert the text into sequences of integers (tokenizer.fit_on_texts)."],"metadata":{"id":"JRqQnx-I5U-J"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.datasets import imdb\n","import numpy as np\n","\n","# Load the IMDb dataset\n","(train_data, _), (test_data, _) = imdb.load_data(num_words=5000)\n","\n","# Convert integer sequences back to text\n","word_index = imdb.get_word_index()\n","reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n","decoded_train_reviews = [' '.join([reverse_word_index.get(i - 3, '?') for i in review]) for review in train_data]\n","decoded_test_reviews = [' '.join([reverse_word_index.get(i - 3, '?') for i in review]) for review in test_data]\n","\n","# Shuffle words within each review\n","shuffled_train_reviews = [' '.join(np.random.permutation(review.split())) for review in decoded_train_reviews]\n","shuffled_test_reviews = [' '.join(np.random.permutation(review.split())) for review in decoded_test_reviews]\n","\n","# Tokenize the text\n","tokenizer = Tokenizer(num_words=5000)\n","tokenizer.fit_on_texts(shuffled_train_reviews)\n","total_words = len(tokenizer.word_index) + 1\n"],"metadata":{"id":"CspRacThDDk6","executionInfo":{"status":"ok","timestamp":1700187133833,"user_tz":300,"elapsed":26143,"user":{"displayName":"Eugene Tye","userId":"03176183298028220664"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Step 2: Pad Sequences and Create Pairs for Self-Supervised Learning"],"metadata":{"id":"TVBltVyU5oYn"}},{"cell_type":"markdown","source":["*   Text is converted to sequences of integers using the tokenizer.\n","*   Sequences are padded to have the same length for modeling convenience (pad_sequences).\n","*   The create_word_pairs function generates pairs of shuffled and original sequences for self-supervised learning."],"metadata":{"id":"LAHpPgMlDMGM"}},{"cell_type":"code","source":["# Convert text to sequences\n","train_sequences = tokenizer.texts_to_sequences(shuffled_train_reviews)\n","test_sequences = tokenizer.texts_to_sequences(shuffled_test_reviews)\n","\n","# Pad sequences to have the same length\n","padded_train_sequences = pad_sequences(train_sequences)\n","padded_test_sequences = pad_sequences(test_sequences, maxlen=len(padded_train_sequences[0]))\n","\n","# Create pairs for self-supervised learning\n","def create_word_pairs(sequences):\n","    pairs = []\n","    for seq in sequences:\n","        pairs.append([seq, np.random.permutation(seq)])\n","    return np.array(pairs)\n"],"metadata":{"id":"0pf7DTuMDY0P","executionInfo":{"status":"ok","timestamp":1700187196642,"user_tz":300,"elapsed":8148,"user":{"displayName":"Eugene Tye","userId":"03176183298028220664"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Step 3: Define and Compile the Model"],"metadata":{"id":"s26affht52vY"}},{"cell_type":"markdown","source":["*   The model architecture is defined for predicting the order of words.\n","*   It consists of an embedding layer, an LSTM layer, and a dense output layer with sigmoid activation.\n","*   The model is compiled with the Adam optimizer, binary crossentropy loss, and accuracy as the metric."],"metadata":{"id":"M7vBqPqqDfIn"}},{"cell_type":"code","source":["# Model for predicting the order of words\n","def word_order_prediction_model(input_size):\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Embedding(input_dim=total_words, output_dim=16, input_length=input_size),\n","        tf.keras.layers.LSTM(32),\n","        tf.keras.layers.Dense(1, activation='sigmoid')\n","    ])\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n"],"metadata":{"id":"Y9LrrZRQDkfV","executionInfo":{"status":"ok","timestamp":1700187235664,"user_tz":300,"elapsed":137,"user":{"displayName":"Eugene Tye","userId":"03176183298028220664"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Step 4: Create Pairs for Self-Supervised Learning on Training Data"],"metadata":{"id":"tBTvAKrR6QiK"}},{"cell_type":"markdown","source":["*   Setting the random seed ensures reproducibility of the experiment.\n","*   Pairs and labels for self-supervised learning are created on the training set.\n","*   The data is shuffled for better training."],"metadata":{"id":"S2CKhP3ID2xZ"}},{"cell_type":"code","source":["# Set random seed for reproducibility\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","# Create pairs for self-supervised learning on the training set\n","word_pairs = create_word_pairs(padded_train_sequences)\n","\n","# Labels for word order prediction (1 for correct order, 0 for incorrect order)\n","word_order_labels = np.ones(len(word_pairs))\n","\n","# Shuffle the data\n","shuffle_index = np.random.permutation(len(word_pairs))\n","word_pairs, word_order_labels = word_pairs[shuffle_index], word_order_labels[shuffle_index]\n"],"metadata":{"id":"qn6GY4_2DzLt","executionInfo":{"status":"ok","timestamp":1700187308365,"user_tz":300,"elapsed":3101,"user":{"displayName":"Eugene Tye","userId":"03176183298028220664"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# Step 5: Train the Model"],"metadata":{"id":"GT1_i0me6eQB"}},{"cell_type":"markdown","source":["*   The model is instantiated, and its architecture is defined using the function from Step 3.\n","*   The model is trained using the self-supervised learning pairs and labels for 3 epochs.\n","*   Each epoch should take about 5 minutes to run."],"metadata":{"id":"iyW2ubwaECIv"}},{"cell_type":"code","source":["# Define the word order prediction model\n","input_size = len(word_pairs[0][0])\n","word_order_model = word_order_prediction_model(input_size)\n","\n","# Train the model\n","word_order_model.fit(word_pairs[:, 0], word_order_labels, epochs=3, batch_size=128)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7B9lIb3C80fJ","executionInfo":{"status":"ok","timestamp":1700191773276,"user_tz":300,"elapsed":868545,"user":{"displayName":"Eugene Tye","userId":"03176183298028220664"}},"outputId":"3c9b0d27-36f3-4f6f-c49a-ef4af505d894"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","196/196 [==============================] - 302s 2s/step - loss: 0.0741 - accuracy: 0.9963\n","Epoch 2/3\n","196/196 [==============================] - 282s 1s/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 3/3\n","196/196 [==============================] - 278s 1s/step - loss: 5.6964e-04 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7b0aa671f370>"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["# Step 6: Evaluate the Model on the Test Set"],"metadata":{"id":"PzeJQGSQEMkv"}},{"cell_type":"markdown","source":["*   create_word_pairs is used to generate pairs for the test set, similar to what was done for the training set. This creates a set of shuffled and original sequences for self-supervised learning.\n","\n","*   test_word_order_labels is created as an array of ones since, in self-supervised learning, the labels are always 1 for correct order.\n","\n","*   word_order_model.evaluate is then called to evaluate the trained model on the test set. This involves predicting the order of words in the shuffled sequences and comparing it with the ground truth (which is always 1 for correct order).\n","\n","*   The evaluation results include the test loss and test accuracy, which are printed to the console for analysis. The test accuracy represents how well the model is able to predict the correct order of words in the shuffled sequences on the test set."],"metadata":{"id":"ToE5WmxkEP9o"}},{"cell_type":"code","source":["# Evaluate the model on the test set\n","test_word_pairs = create_word_pairs(padded_test_sequences)\n","test_word_order_labels = np.ones(len(test_word_pairs))\n","\n","evaluation_results = word_order_model.evaluate(test_word_pairs[:, 0], test_word_order_labels)\n","print(f\"Test Loss: {evaluation_results[0]}, Test Accuracy: {evaluation_results[1]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QI4MvxPPEMVg","executionInfo":{"status":"ok","timestamp":1700192661921,"user_tz":300,"elapsed":205656,"user":{"displayName":"Eugene Tye","userId":"03176183298028220664"}},"outputId":"b6509050-6cc3-4994-9ed9-057d40f65c9a"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["782/782 [==============================] - 149s 190ms/step - loss: 4.3223e-04 - accuracy: 1.0000\n","Test Loss: 0.0004322270688135177, Test Accuracy: 1.0\n"]}]}]}